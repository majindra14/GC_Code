{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import openpyxl\n",
    "from statistics import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = openpyxl.load_workbook('GCData-JGI_ACRs.xlsx')\n",
    "sheet_input = wb['EXT_STD']\n",
    "#sheet_output = wb['Output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3_area = (8532, 49732, 84584, 522428, 1173482)\n",
      "C3_conc = (10, 50, 100, 500, 1000)\n",
      "C4_area = ('-', '-', 88719, 558171, 1200840)\n",
      "C4_conc = (10, 50, 100, 500, 1000)\n",
      "C5_area = (10399, 60722, 102033, 629568, 1349065)\n",
      "C5_conc = (10, 50, 100, 500, 1000)\n",
      "C6_area = (11682, 65225, 110204, 674684, 1436164)\n",
      "C6_conc = (10, 50, 100, 500, 1000)\n",
      "C7_area = (12433, 69285, 117473, 723636, 1541657)\n",
      "C7_conc = (10, 50, 100, 500, 1000)\n",
      "C8_area = (12565, 70574, 119219, 741113, 1569109)\n",
      "C8_conc = (10, 50, 100, 500, 1000)\n",
      "C9_area = (14310, 75654, 129758, 783067, 1641564)\n",
      "C9_conc = (10, 50, 100, 500, 1000)\n",
      "C10_area = (13971, 72999, 123707, 759364, 1594623)\n",
      "C10_conc = (10, 50, 100, 500, 1000)\n",
      "C11_area = (15779, 75524, 127807, 770885, 1610748)\n",
      "C11_conc = (10, 50, 100, 500, 1000)\n",
      "C12_area = (14434, 76281, 130654, 792655, 1651935)\n",
      "C12_conc = (10, 50, 100, 500, 1000)\n",
      "C13_area = (15300, 79878, 135899, 817412, 1702502)\n",
      "C13_conc = (10, 50, 100, 500, 1000)\n",
      "C14_area = (15444, 80042, 136408, 812260, 1676817)\n",
      "C14_conc = (10, 50, 100, 500, 1000)\n",
      "C15_area = (17293, 83765, 143952, 834814, 1716066)\n",
      "C15_conc = (10, 50, 100, 500, 1000)\n",
      "C16_area = (17051, 77955, 133034, 754187, 1536311)\n",
      "C16_conc = (10, 50, 100, 500, 1000)\n",
      "C17_area = (18929, 76303, 132062, 712350, 1369390)\n",
      "C17_conc = (10, 50, 100, 500, 1000)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9e8f08f36e0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msheet_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues_only\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# skips first two rows and starts at 3rd row, which contains ext standard concentrations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_area = '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_conc = '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "# Parses through external standard concentrations from EXT_STD tab and outputs the variables to be copied into below block\n",
    "\n",
    "i = 0\n",
    "\n",
    "for row in sheet_input.iter_rows(min_row = 1, max_row = 100, min_col = 1, max_col = 100, values_only = True):   \n",
    "    if i > 1: # skips first two rows and starts at 3rd row, which contains ext standard concentrations\n",
    "        print(row[0] + '_area = ' + str(row[2:12:2]))\n",
    "        print(row[0] + '_conc = ' + str(row[1:11:2]))\n",
    "        \n",
    "    i = i + 1\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### User enters data here, copied from output from above block\n",
    "\n",
    "#Enter external standard peak areas. Replace individual default_conc if needed\n",
    "\n",
    "C3_area = (8532, 49732, 84584, 522428, 1173482)\n",
    "C3_conc = (10, 50, 100, 500, 1000)\n",
    "C4_area = ('-', '-', 88719, 558171, 1200840)\n",
    "C4_conc = (10, 50, 100, 500, 1000)\n",
    "C5_area = (10399, 60722, 102033, 629568, 1349065)\n",
    "C5_conc = (10, 50, 100, 500, 1000)\n",
    "C6_area = (11682, 65225, 110204, 674684, 1436164)\n",
    "C6_conc = (10, 50, 100, 500, 1000)\n",
    "C7_area = (12433, 69285, 117473, 723636, 1541657)\n",
    "C7_conc = (10, 50, 100, 500, 1000)\n",
    "C8_area = (12565, 70574, 119219, 741113, 1569109)\n",
    "C8_conc = (10, 50, 100, 500, 1000)\n",
    "C9_area = (14310, 75654, 129758, 783067, 1641564)\n",
    "C9_conc = (10, 50, 100, 500, 1000)\n",
    "C10_area = (13971, 72999, 123707, 759364, 1594623)\n",
    "C10_conc = (10, 50, 100, 500, 1000)\n",
    "C11_area = (15779, 75524, 127807, 770885, 1610748)\n",
    "C11_conc = (10, 50, 100, 500, 1000)\n",
    "C12_area = (14434, 76281, 130654, 792655, 1651935)\n",
    "C12_conc = (10, 50, 100, 500, 1000)\n",
    "C13_area = (15300, 79878, 135899, 817412, 1702502)\n",
    "C13_conc = (10, 50, 100, 500, 1000)\n",
    "C14_area = (15444, 80042, 136408, 812260, 1676817)\n",
    "C14_conc = (10, 50, 100, 500, 1000)\n",
    "C15_area = (17293, 83765, 143952, 834814, 1716066)\n",
    "C15_conc = (10, 50, 100, 500, 1000)\n",
    "C16_area = (17051, 77955, 133034, 754187, 1536311)\n",
    "C16_conc = (10, 50, 100, 500, 1000)\n",
    "C17_area = (18929, 76303, 132062, 712350, 1369390)\n",
    "C17_conc = (10, 50, 100, 500, 1000)\n",
    "\n",
    "\n",
    "\n",
    "#Dictionary containing linear slope fit to peak area vs concentration. Add to dictionary if needed.\n",
    "area_to_conc_scale = {'C7'  : np.polyfit(C7_conc,C7_area,1)[0], \n",
    "                      'C8'  : np.polyfit(C8_conc,C8_area,1)[0],\n",
    "                      'C9'  : np.polyfit(C9_conc,C9_area,1)[0],\n",
    "                      'C10' : np.polyfit(C10_conc,C10_area,1)[0],\n",
    "                      'C11' : np.polyfit(C11_conc,C11_area,1)[0],\n",
    "                      'C12' : np.polyfit(C12_conc,C12_area,1)[0],\n",
    "                      'C13' : np.polyfit(C13_conc,C13_area,1)[0],\n",
    "                      'C14' : np.polyfit(C14_conc,C14_area,1)[0],\n",
    "                      'C15' : np.polyfit(C15_conc,C15_area,1)[0],\n",
    "                      'C16' : np.polyfit(C16_conc,C16_area,1)[0],\n",
    "                      'C17' : np.polyfit(C17_conc,C17_area,1)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C7 1546.91936808\n",
      "C8 1575.68053916\n",
      "C9 1647.37435205\n",
      "C10 1600.88394895\n",
      "C11 1615.58794906\n",
      "C12 1658.77874571\n",
      "C13 1708.57337943\n",
      "C14 1682.94536459\n",
      "C15 1720.34899084\n",
      "C16 1538.5134424\n",
      "C17 1372.03625119\n"
     ]
    }
   ],
   "source": [
    "for x, y in area_to_conc_scale.items():\n",
    "  print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-819be492d670>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#New file will be created with name given by the saveAs variable with a new worksheet called \"Corrected Concentration\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marea_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchain_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint_sdt_conc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveAs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-37bc09aa37f7>\u001b[0m in \u001b[0;36mgetData\u001b[1;34m(file, sheet_name, area_col, chain_col, scale, int_std_conc, saveAs)\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mdfList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mdfList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m#Calculate Scaling Factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdfList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "### Enter internal standard concentrations\n",
    "\n",
    "internalConc = {'C7' : 100, 'C9' : 100, 'C11' : 100, 'C13' : 100, 'C15' : 100, 'C17' : 100}\n",
    "\n",
    "file = 'GCData-JGI_ACRs.xlsx' #file name\n",
    "sheet = 'Quantification w IS,ES' #sheet with peak area and chain identification data\n",
    "area_col = 3 #column number of peak area data (1st column is column 0, 2nd column is column 1, etc.)\n",
    "chain_col = 5 #column number of chain identification data (1st column is column 0, 2nd column is column 1, etc.)\n",
    "scale = area_to_conc_scale #dictionary of scale factors to turn area data into concentration data\n",
    "int_sdt_conc = internalConc #dictionary of internal standard concentrations\n",
    "saveAs = 'GCData-JGI_ACRs w Conc Data.xlsx' #name to save new file\n",
    "\n",
    "#New file will be created with name given by the saveAs variable with a new worksheet called \"Corrected Concentration\"\n",
    "getData(file, sheet, area_col, chain_col, scale, int_sdt_conc, saveAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates and creates a sheet with corrected concentration data\n",
    "# file         - file name\n",
    "# sheet        - sheet with data organized by sample with peak areas and chain lengths identified already\n",
    "# area_col     - column number of peak area data (1st column is column 0, 2nd column is column 1, etc.)\n",
    "# chain_col    - column number of chain indentification data (1st column is column 0, 2nd column is column 1, etc.)\n",
    "# scale        - dictionary of scale factors to turn area data into concentration data\n",
    "# int_std_conc - dictionary of internal standard concentrations\n",
    "\n",
    "def getData (file, sheet_name, area_col, chain_col, scale, int_std_conc, saveAs):\n",
    "    col = [area_col, chain_col]\n",
    "    wb = openpyxl.load_workbook(file)\n",
    "    sheet = wb[sheet_name]\n",
    "    orig = pd.read_excel(file, sheet_name=sheet_name)\n",
    "    df = pd.read_excel(file, sheet_name=sheet_name, usecols = col)\n",
    "    \n",
    "    #add 4 empty columns\n",
    "    df['Pfleger'] = \"\"\n",
    "    df['Lab'] = \"\"\n",
    "    df['For'] = \"\"\n",
    "    df['Life'] = \"\"\n",
    "    \n",
    "    dfList = df.values.tolist()\n",
    "    \n",
    "    # Calculate\n",
    "    for row in range(len(dfList)):\n",
    "        chain = dfList[row][1]\n",
    "        area = dfList[row][0]\n",
    "        #Calculate Uncorrected Concentration\n",
    "        if math.isnan(area):\n",
    "            if chain != chain:\n",
    "                dfList[row][2] = \"\"\n",
    "            else:\n",
    "                dfList[row][2] = 0\n",
    "        else:\n",
    "            dfList[row][2] = dfList[row][0]/scale.get(chain)\n",
    "        #Calculate Scaling Factor\n",
    "        if dfList[row][2] != \"\" and int(chain[len(chain)-1])%2 == 1:\n",
    "            dfList[row][3] = dfList[row][2]/int_std_conc[chain]\n",
    "    \n",
    "    #Calculate Averaged Scaling Factors and Corrected Concentrations\n",
    "    for row in range(len(dfList)):\n",
    "        chain = dfList[row][1]\n",
    "        area = dfList[row][0]\n",
    "        if dfList[row][2] != \"\" and int(chain[len(chain)-1])%2 == 0:\n",
    "            dfList[row][4] = mean([dfList[row-1][3],dfList[row+1][3]])\n",
    "            dfList[row][5] = dfList[row][2]/dfList[row][4]\n",
    "    \n",
    "    #modify data type to allow python to write to excel\n",
    "    dfList = np.array(dfList)\n",
    "    concDataDict = {'Uncorrected Concentration' :dfList[:,2].tolist(), \n",
    "                    'Scaling Factor':dfList[:,3].tolist(), \n",
    "                    'Averaged Scaling Factor':dfList[:,4].tolist(), \n",
    "                    'Corrected Concentration':dfList[:,5].tolist()}\n",
    "    order = ['Uncorrected Concentration','Scaling Factor','Averaged Scaling Factor','Corrected Concentration']\n",
    "    concData = pd.DataFrame(concDataDict, columns = order)\n",
    "    excelData = pd.concat([orig, concData], axis = 1)\n",
    "    \n",
    "    #write to the excel file\n",
    "    writer = pd.ExcelWriter(file, engine = 'openpyxl')\n",
    "    writer.book = wb\n",
    "    excelData.to_excel(writer, sheet_name = \"Corrected Concentration\", index = False, startrow = 0, startcol = 0)\n",
    "    wb.save(filename = saveAs)\n",
    "    return excelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cameo3.4]",
   "language": "python",
   "name": "conda-env-cameo3.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
